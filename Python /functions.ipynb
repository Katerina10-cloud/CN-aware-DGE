{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d404de7-e0fe-435c-9549-345b24a868e5",
   "metadata": {},
   "source": [
    "## Fit a NB GLM wit log-link to predict counts from the design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6487e3-764e-4422-aa3b-63762794114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def irls_solver(\n",
    "    counts: np.ndarray,\n",
    "    size_factors: np.ndarray,\n",
    "    design_matrix: np.ndarray,\n",
    "    disp: float,\n",
    "    min_mu: float = 0.5,\n",
    "    beta_tol: float = 1e-8,\n",
    "    min_beta: float = -30,\n",
    "    max_beta: float = 30,\n",
    "    optimizer: Literal[\"BFGS\", \"L-BFGS-B\"] = \"L-BFGS-B\",\n",
    "    maxiter: int = 250,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, bool]:\n",
    "    r\"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : ndarray\n",
    "        Raw counts for a given gene.\n",
    "\n",
    "    size_factors : ndarray\n",
    "        Sample-wise scaling factors (obtained from median-of-ratios).\n",
    "\n",
    "    design_matrix : ndarray\n",
    "        Design matrix.\n",
    "\n",
    "    disp : float\n",
    "        Gene-wise dispersion prior.\n",
    "\n",
    "    min_mu : float\n",
    "        Lower bound on estimated means, to ensure numerical stability.\n",
    "        (default: ``0.5``).\n",
    "\n",
    "    beta_tol : float\n",
    "        Stopping criterion for IRWLS:\n",
    "        :math:`\\vert dev - dev_{old}\\vert / \\vert dev + 0.1 \\vert < \\beta_{tol}`.\n",
    "        (default: ``1e-8``).\n",
    "\n",
    "    min_beta : float\n",
    "        Lower-bound on LFC. (default: ``-30``).\n",
    "\n",
    "    max_beta : float\n",
    "        Upper-bound on LFC. (default: ``30``).\n",
    "\n",
    "    optimizer : str\n",
    "        Optimizing method to use in case IRLS starts diverging.\n",
    "        Accepted values: 'BFGS' or 'L-BFGS-B'.\n",
    "        NB: only 'L-BFGS-B' ensures that LFCS will\n",
    "        lay in the [min_beta, max_beta] range. (default: ``'L-BFGS-B'``).\n",
    "\n",
    "    maxiter : int\n",
    "        Maximum number of IRLS iterations to perform before switching to L-BFGS-B.\n",
    "        (default: ``250``).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    beta: ndarray\n",
    "        Fitted (basemean, lfc) coefficients of negative binomial GLM.\n",
    "\n",
    "    mu: ndarray\n",
    "        Means estimated from size factors and beta: :math:`\\mu = s_{ij} \\exp(\\beta^t X)`.\n",
    "\n",
    "    H: ndarray\n",
    "        Diagonal of the :math:`W^{1/2} X (X^t W X)^-1 X^t W^{1/2}` covariance matrix.\n",
    "\n",
    "    converged: bool\n",
    "        Whether IRLS or the optimizer converged. If not and if dimension allows it,\n",
    "        perform grid search.\n",
    "    \"\"\"\n",
    "    assert optimizer in [\"BFGS\", \"L-BFGS-B\"]\n",
    "\n",
    "    num_vars = design_matrix.shape[1]\n",
    "    X = design_matrix\n",
    "\n",
    "    # if full rank, estimate initial betas for IRLS below\n",
    "    if np.linalg.matrix_rank(X) == num_vars:\n",
    "        Q, R = np.linalg.qr(X)\n",
    "        y = np.log(counts / size_factors + 0.1)\n",
    "        beta_init = solve(R, Q.T @ y)\n",
    "        beta = beta_init\n",
    "    else:  # Initialise intercept with log base mean\n",
    "        beta = np.zeros(num_vars)\n",
    "        beta[0] = np.log(counts / size_factors).mean()\n",
    "\n",
    "    dev = 1000.0\n",
    "    dev_ratio = 1.0\n",
    "\n",
    "    ridge_factor = np.diag(np.repeat(1e-6, num_vars))\n",
    "    mu = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "\n",
    "    converged = True\n",
    "    i = 0\n",
    "    while dev_ratio > beta_tol:\n",
    "        W = mu / (1.0 + mu * disp)\n",
    "        z = np.log(mu / size_factors) + (counts - mu) / mu\n",
    "        H = (X.T * W) @ X + ridge_factor\n",
    "        beta_hat = solve(H, X.T @ (W * z), assume_a=\"pos\")\n",
    "        i += 1\n",
    "\n",
    "        if sum(np.abs(beta_hat) > max_beta) > 0 or i >= maxiter:\n",
    "            # If IRLS starts diverging, use L-BFGS-B\n",
    "            def f(beta: np.ndarray) -> float:\n",
    "                # closure to minimize\n",
    "                mu_ = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "                return nb_nll(counts, mu_, disp) + 0.5 * (ridge_factor @ beta**2).sum()\n",
    "\n",
    "            def df(beta: np.ndarray) -> np.ndarray:\n",
    "                mu_ = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "                return (\n",
    "                    -X.T @ counts\n",
    "                    + ((1 / disp + counts) * mu_ / (1 / disp + mu_)) @ X\n",
    "                    + ridge_factor @ beta\n",
    "                )\n",
    "\n",
    "            res = minimize(\n",
    "                f,\n",
    "                beta_init,\n",
    "                jac=df,\n",
    "                method=optimizer,\n",
    "                bounds=(\n",
    "                    [(min_beta, max_beta)] * num_vars\n",
    "                    if optimizer == \"L-BFGS-B\"\n",
    "                    else None\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            beta = res.x\n",
    "            mu = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "            converged = res.success\n",
    "\n",
    "            if not res.success and num_vars <= 2:\n",
    "                beta = grid_fit_beta(\n",
    "                    counts,\n",
    "                    size_factors,\n",
    "                    X,\n",
    "                    disp,\n",
    "                )\n",
    "                mu = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "            break\n",
    "\n",
    "        beta = beta_hat\n",
    "        mu = np.maximum(size_factors * np.exp(X @ beta), min_mu)\n",
    "        # Compute deviation\n",
    "        old_dev = dev\n",
    "        # Replaced deviation with -2 * nll, as in the R code\n",
    "        dev = -2 * nb_nll(counts, mu, disp)\n",
    "        dev_ratio = np.abs(dev - old_dev) / (np.abs(dev) + 0.1)\n",
    "\n",
    "    # Compute H diagonal (useful for Cook distance outlier filtering)\n",
    "    W = mu / (1.0 + mu * disp)\n",
    "    W_sq = np.sqrt(W)\n",
    "    XtWX = (X.T * W) @ X + ridge_factor\n",
    "    H = W_sq * np.diag(X @ np.linalg.inv(XtWX) @ X.T) * W_sq\n",
    "    # Return an UNthresholded mu (as in the R code)\n",
    "    # Previous quantities are estimated with a threshold though\n",
    "    mu = size_factors * np.exp(X @ beta)\n",
    "    return beta, mu, H, converged\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11226147-2e0d-4ccd-82b0-48ee94a10607",
   "metadata": {},
   "source": [
    "# Copy-Number-aware Differential Gene Expression\n",
    "\n",
    "## Pydeseq2CN test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3dc930a-450a-4306-b5ac-7aeb08782ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import multiprocessing\n",
    "import warnings\n",
    "from math import floor\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from typing import Literal\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Union\n",
    "from typing import cast\n",
    "\n",
    "import os\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a11a7e3-a529-476c-b3f9-7e2006954d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad  # type: ignore\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm  # type: ignore\n",
    "from joblib import Parallel  # type: ignore\n",
    "from joblib import delayed\n",
    "from joblib import parallel_backend\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import gammaln \n",
    "from scipy.special import polygamma  # type: ignore\n",
    "from scipy.stats import f  # type: ignore\n",
    "from scipy.stats import trim_mean  # type: ignore\n",
    "from scipy.stats import norm\n",
    "from statsmodels.tools.sm_exceptions import DomainWarning  # type: ignore\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4528e647-27e9-4539-a874-30d26b3cb348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydeseq2\n",
    "from pydeseq2.preprocessing import deseq2_norm\n",
    "from pydeseq2.utils import build_design_matrix\n",
    "from pydeseq2.utils import dispersion_trend\n",
    "from pydeseq2.utils import fit_alpha_mle\n",
    "from pydeseq2.utils import fit_lin_mu\n",
    "from pydeseq2.utils import fit_moments_dispersions\n",
    "from pydeseq2.utils import fit_rough_dispersions\n",
    "from pydeseq2.utils import irls_solver\n",
    "from pydeseq2.utils import get_num_processes\n",
    "from pydeseq2.utils import make_scatter\n",
    "from pydeseq2.utils import mean_absolute_deviation\n",
    "from pydeseq2.utils import nb_nll\n",
    "from pydeseq2.utils import replace_underscores\n",
    "from pydeseq2.utils import robust_method_of_moments_disp\n",
    "from pydeseq2.utils import test_valid_counts\n",
    "from pydeseq2.utils import trimmed_mean\n",
    "\n",
    "from pydeseq2.grid_search import grid_fit_alpha\n",
    "from pydeseq2.grid_search import grid_fit_beta\n",
    "\n",
    "from pydeseq2.ds import DeseqStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa206e1-2176-4d17-a184-259c1cc54521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore DomainWarning raised by statsmodels when fitting a Gamma GLM with identity link.\n",
    "warnings.simplefilter(\"ignore\", DomainWarning)\n",
    "# Ignore AnnData's FutureWarning about implicit data conversion.\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45bf0b-346f-4105-b660-c75965557b79",
   "metadata": {},
   "source": [
    "### Model fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66f720c-3b41-4e88-a886-3ffc2cf5357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeseqDataSet(ad.AnnData):\n",
    "    def __init__(self,\n",
    "        *,\n",
    "        adata: Optional[ad.AnnData] = None,\n",
    "        counts: Optional[pd.DataFrame] = None,\n",
    "        metadata: Optional[pd.DataFrame] = None,\n",
    "        design_factors: Union[str, List[str]] = \"condition\",\n",
    "        continuous_factors: Optional[List[str]] = None,\n",
    "        ref_level: Optional[List[str]] = None,\n",
    "        min_mu: float = 0.5,\n",
    "        min_disp: float = 1e-8,\n",
    "        max_disp: float = 10.0,\n",
    "        refit_cooks: bool = True,\n",
    "        min_replicates: int = 7,\n",
    "        beta_tol: float = 1e-8,\n",
    "        n_cpus: Optional[int] = None,\n",
    "        batch_size: int = 128,\n",
    "        joblib_verbosity: int = 0,\n",
    "        quiet: bool = False,\n",
    "    ) -> None:\n",
    "        # Initialize the AnnData part\n",
    "        if adata is not None:\n",
    "            if counts is not None:\n",
    "                warnings.warn(\n",
    "                    \"adata was provided; ignoring counts.\", UserWarning, stacklevel=2\n",
    "                )\n",
    "            if metadata is not None:\n",
    "                warnings.warn(\n",
    "                    \"adata was provided; ignoring metadata.\", UserWarning, stacklevel=2\n",
    "                )\n",
    "            # Test counts before going further\n",
    "            #test_valid_counts(adata.X)\n",
    "            # Copy fields from original AnnData\n",
    "            self.__dict__.update(adata.__dict__)\n",
    "        \n",
    "        elif counts is not None and metadata is not None:\n",
    "            # Test counts before going further\n",
    "            #test_valid_counts(counts)\n",
    "            super().__init__(X=counts, obs=metadata)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Either adata or both counts and metadata arguments must be provided.\"\n",
    "            )\n",
    "            \n",
    "         # Convert design_factors to list if a single string was provided.\n",
    "        self.design_factors = (\n",
    "            [design_factors] if isinstance(design_factors, str) else design_factors\n",
    "        )\n",
    "        self.continuous_factors = continuous_factors\n",
    "        \n",
    "        if self.obs[self.design_factors].isna().any().any():\n",
    "            raise ValueError(\"NaNs are not allowed in the design factors.\")\n",
    "        self.obs[self.design_factors] = self.obs[self.design_factors].astype(str)\n",
    "        \n",
    "        # Check that design factors don't contain underscores. If so, convert them to\n",
    "        # hyphens.\n",
    "        if np.any([\"_\" in factor for factor in self.design_factors]):\n",
    "            warnings.warn(\n",
    "                \"\"\"Same factor names in the design contain underscores ('_'). They will\n",
    "                be converted to hyphens ('-').\"\"\",\n",
    "                UserWarning,\n",
    "                stacklevel=2,\n",
    "            )\n",
    "\n",
    "            new_factors = replace_underscores(self.design_factors)\n",
    "\n",
    "            self.obs.rename(\n",
    "                columns={\n",
    "                    old_factor: new_factor\n",
    "                    for (old_factor, new_factor) in zip(self.design_factors, new_factors)\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "            self.design_factors = new_factors\n",
    "\n",
    "            # Also check continuous factors\n",
    "            if self.continuous_factors is not None:\n",
    "                self.continuous_factors = replace_underscores(self.continuous_factors)\n",
    "\n",
    "        # If ref_level has underscores, covert them to hyphens\n",
    "        # Don't raise a warning: it will be raised by build_design_matrix()\n",
    "        if ref_level is not None:\n",
    "            ref_level = replace_underscores(ref_level)\n",
    "        \n",
    "        # Build the design matrix\n",
    "        # Stored in the obsm attribute of the dataset\n",
    "        self.obsm[\"design_matrix\"] = build_design_matrix(\n",
    "            metadata=self.obs,\n",
    "            design_factors=self.design_factors,\n",
    "            continuous_factors=self.continuous_factors,\n",
    "            ref_level=ref_level,\n",
    "            expanded=False,\n",
    "            intercept=True,\n",
    "        )\n",
    "        \n",
    "        # Check that the design matrix has full rank\n",
    "        self._check_full_rank_design()\n",
    "        \n",
    "        self.min_mu = min_mu\n",
    "        self.min_disp = min_disp\n",
    "        self.max_disp = np.maximum(max_disp, self.n_obs)\n",
    "        self.refit_cooks = refit_cooks\n",
    "        self.ref_level = ref_level\n",
    "        self.min_replicates = min_replicates\n",
    "        self.beta_tol = beta_tol\n",
    "        self.n_processes = get_num_processes(n_cpus)\n",
    "        self.batch_size = batch_size\n",
    "        self.joblib_verbosity = joblib_verbosity\n",
    "        self.quiet = quiet\n",
    "    \n",
    "    def vst(\n",
    "        self,\n",
    "        use_design: bool = False,\n",
    "        fit_type: Literal[\"parametric\", \"mean\"] = \"parametric\",\n",
    "    ) -> None:\n",
    "        # Start by fitting median-of-ratio size factors, if not already present.\n",
    "        if \"size_factors\" not in self.obsm:\n",
    "            self.fit_size_factors()\n",
    "\n",
    "        if use_design:\n",
    "            # Check that the dispersion trend curve was fitted. If not, fit it.\n",
    "            # This will call previous functions in a cascade.\n",
    "            if \"trend_coeffs\" not in self.uns:\n",
    "                self.fit_dispersion_trend()\n",
    "        else:\n",
    "            # Reduce the design matrix to an intercept and reconstruct at the end\n",
    "            self.obsm[\"design_matrix_buffer\"] = self.obsm[\"design_matrix\"].copy()\n",
    "            self.obsm[\"design_matrix\"] = pd.DataFrame(\n",
    "                1, index=self.obs_names, columns=[[\"intercept\"]]\n",
    "            )\n",
    "            # Fit the trend curve with an intercept design\n",
    "            self.fit_genewise_dispersions()\n",
    "            if fit_type == \"parametric\":\n",
    "                self.fit_dispersion_trend()\n",
    "\n",
    "            # Restore the design matrix and free buffer\n",
    "            self.obsm[\"design_matrix\"] = self.obsm[\"design_matrix_buffer\"].copy()\n",
    "            del self.obsm[\"design_matrix_buffer\"]\n",
    "\n",
    "        # Apply VST\n",
    "        if fit_type == \"parametric\":\n",
    "            a0, a1 = self.uns[\"trend_coeffs\"]\n",
    "            cts = self.layers[\"normed_counts\"]\n",
    "            self.layers[\"vst_counts\"] = np.log2(\n",
    "                (1 + a1 + 2 * a0 * cts + 2 * np.sqrt(a0 * cts * (1 + a1 + a0 * cts)))\n",
    "                / (4 * a0)\n",
    "            )\n",
    "        elif fit_type == \"mean\":\n",
    "            gene_dispersions = self.varm[\"genewise_dispersions\"]\n",
    "            use_for_mean = gene_dispersions > 10 * self.min_disp\n",
    "            mean_disp = trim_mean(gene_dispersions[use_for_mean], proportiontocut=0.001)\n",
    "            self.layers[\"vst_counts\"] = (\n",
    "                2 * np.arcsinh(np.sqrt(mean_disp * self.layers[\"normed_counts\"]))\n",
    "                - np.log(mean_disp)\n",
    "                - np.log(4)\n",
    "            ) / np.log(2)\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                f\"Found fit_type '{fit_type}'. Expected 'parametric' or 'mean'.\"\n",
    "            )\n",
    "            \n",
    "    def deseq2(self) -> None:\n",
    "        \n",
    "        \"\"\"Perform dispersion and log fold-change (LFC) estimation.\n",
    "\n",
    "        \"\"\"\n",
    "        # Compute DESeq2 normalization factors using the Median-of-ratios method\n",
    "        self.fit_size_factors()\n",
    "        # Fit an independent negative binomial model per gene\n",
    "        self.fit_genewise_dispersions()\n",
    "        # Fit a parameterized trend curve for dispersions, of the form\n",
    "        self.fit_dispersion_trend()\n",
    "        # Compute prior dispersion variance\n",
    "        self.fit_dispersion_prior()\n",
    "        # Refit genewise dispersions a posteriori (shrinks estimates towards trend curve)\n",
    "        self.fit_MAP_dispersions()\n",
    "        # Fit log-fold changes (in natural log scale)\n",
    "        self.fit_LFC()\n",
    "        self.calculate_cooks()\n",
    "        \n",
    "        if self.refit_cooks:\n",
    "            # Replace outlier counts, and refit dispersions and LFCs\n",
    "            # for genes that had outliers replaced\n",
    "            self.refit()\n",
    "        \n",
    "    def fit_size_factors(\n",
    "        self, fit_type: Literal[\"ratio\", \"iterative\"] = \"ratio\"\n",
    "    ) -> None:\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting size factors...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        if fit_type == \"iterative\":\n",
    "            self._fit_iterate_size_factors()\n",
    "        # Test whether it is possible to use median-of-ratios.\n",
    "        elif (self.X == 0).any(0).all():\n",
    "            # There is at least a zero for each gene\n",
    "            warnings.warn(\n",
    "                \"Every gene contains at least one zero, \"\n",
    "                \"cannot compute log geometric means. Switching to iterative mode.\",\n",
    "                RuntimeWarning,\n",
    "                stacklevel=2,\n",
    "            )\n",
    "            self._fit_iterate_size_factors()\n",
    "        else:\n",
    "            self.layers[\"normed_counts\"], self.obsm[\"size_factors\"] = deseq2_norm(self.X)\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end - start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "            \n",
    "    \n",
    "    def fit_genewise_dispersions(self) -> None:\n",
    "        \"\"\"Fit gene-wise dispersion estimates.\n",
    "\n",
    "        Fits a negative binomial per gene, independently.\n",
    "        \"\"\"\n",
    "        # Check that size factors are available. If not, compute them.\n",
    "        if \"size_factors\" not in self.obsm:\n",
    "            self.fit_size_factors()\n",
    "\n",
    "        # Exclude genes with all zeroes\n",
    "        self.varm[\"non_zero\"] = ~(self.X == 0).all(axis=0)\n",
    "        self.non_zero_idx = np.arange(self.n_vars)[self.varm[\"non_zero\"]]\n",
    "        self.non_zero_genes = self.var_names[self.varm[\"non_zero\"]]\n",
    "\n",
    "        if isinstance(self.non_zero_genes, pd.MultiIndex):\n",
    "            raise ValueError(\"non_zero_genes should not be a MultiIndex\")\n",
    "\n",
    "        # Fit \"method of moments\" dispersion estimates\n",
    "        self._fit_MoM_dispersions()\n",
    "\n",
    "        # Convert design_matrix to numpy for speed\n",
    "        design_matrix = self.obsm[\"design_matrix\"].values\n",
    "        \n",
    "        if (\n",
    "            len(self.obsm[\"design_matrix\"].value_counts())\n",
    "            == self.obsm[\"design_matrix\"].shape[-1]\n",
    "        ):\n",
    "            with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "                mu_hat_ = np.array(\n",
    "                    Parallel(\n",
    "                        n_jobs=self.n_processes,\n",
    "                        verbose=self.joblib_verbosity,\n",
    "                        batch_size=self.batch_size,\n",
    "                    )(\n",
    "                        delayed(fit_lin_mu)(\n",
    "                            counts=self.X[:, i],\n",
    "                            size_factors=self.obsm[\"size_factors\"],\n",
    "                            design_matrix=design_matrix,\n",
    "                            min_mu=self.min_mu,\n",
    "                        )\n",
    "                        for i in self.non_zero_idx\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "                res = Parallel(\n",
    "                    n_jobs=self.n_processes,\n",
    "                    verbose=self.joblib_verbosity,\n",
    "                    batch_size=self.batch_size,\n",
    "                )(\n",
    "                    delayed(irls_solver)(\n",
    "                        counts=self.X[:, i],\n",
    "                        size_factors=self.obsm[\"size_factors\"],\n",
    "                        design_matrix=design_matrix,\n",
    "                        disp=self.varm[\"_MoM_dispersions\"][i],\n",
    "                        min_mu=self.min_mu,\n",
    "                        beta_tol=self.beta_tol,\n",
    "                    )\n",
    "                    for i in self.non_zero_idx\n",
    "                )\n",
    "\n",
    "                _, mu_hat_, _, _ = zip(*res)\n",
    "                mu_hat_ = np.array(mu_hat_)\n",
    "\n",
    "        self.layers[\"_mu_hat\"] = np.full((self.n_obs, self.n_vars), np.NaN)\n",
    "        self.layers[\"_mu_hat\"][:, self.varm[\"non_zero\"]] = mu_hat_.T\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting dispersions...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "            res = Parallel(\n",
    "                n_jobs=self.n_processes,\n",
    "                verbose=self.joblib_verbosity,\n",
    "                batch_size=self.batch_size,\n",
    "            )(\n",
    "                delayed(fit_alpha_mle)(\n",
    "                    counts=self.X[:, i],\n",
    "                    design_matrix=design_matrix,\n",
    "                    mu=self.layers[\"_mu_hat\"][:, i],\n",
    "                    alpha_hat=self.varm[\"_MoM_dispersions\"][i],\n",
    "                    min_disp=self.min_disp,\n",
    "                    max_disp=self.max_disp,\n",
    "                )\n",
    "                # for i in range(num_genes)\n",
    "                for i in self.non_zero_idx\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end - start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        dispersions_, l_bfgs_b_converged_ = zip(*res)\n",
    "\n",
    "        self.varm[\"genewise_dispersions\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"genewise_dispersions\"][self.varm[\"non_zero\"]] = np.clip(\n",
    "            dispersions_, self.min_disp, self.max_disp\n",
    "        )\n",
    "\n",
    "        self.varm[\"_genewise_converged\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"_genewise_converged\"][self.varm[\"non_zero\"]] = l_bfgs_b_converged_\n",
    "        \n",
    "    \n",
    "    def fit_dispersion_trend(self) -> None:\n",
    "        r\"\"\"Fit the dispersion trend coefficients.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that genewise dispersions are available. If not, compute them.\n",
    "        if \"genewise_dispersions\" not in self.varm:\n",
    "            self.fit_genewise_dispersions()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting dispersion trend curve...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        self.varm[\"_normed_means\"] = self.layers[\"normed_counts\"].mean(0)\n",
    "\n",
    "        # Exclude all-zero counts\n",
    "        targets = pd.Series(\n",
    "            self[:, self.non_zero_genes].varm[\"genewise_dispersions\"].copy(),\n",
    "            index=self.non_zero_genes,\n",
    "        )\n",
    "        covariates = sm.add_constant(\n",
    "            pd.Series(\n",
    "                1 / self[:, self.non_zero_genes].varm[\"_normed_means\"],\n",
    "                index=self.non_zero_genes,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for gene in self.non_zero_genes:\n",
    "            if (\n",
    "                np.isinf(covariates.loc[gene]).any()\n",
    "                or np.isnan(covariates.loc[gene]).any()\n",
    "            ):\n",
    "                targets.drop(labels=[gene], inplace=True)\n",
    "                covariates.drop(labels=[gene], inplace=True)\n",
    "\n",
    "        # Initialize coefficients\n",
    "        old_coeffs = pd.Series([0.1, 0.1])\n",
    "        coeffs = pd.Series([1.0, 1.0])\n",
    "\n",
    "        while (np.log(np.abs(coeffs / old_coeffs)) ** 2).sum() >= 1e-6:\n",
    "            glm_gamma = sm.GLM(\n",
    "                targets.values,\n",
    "                covariates.values,\n",
    "                family=sm.families.Gamma(link=sm.families.links.identity()),\n",
    "            )\n",
    "\n",
    "            res = glm_gamma.fit()\n",
    "            old_coeffs = coeffs.copy()\n",
    "            coeffs = res.params\n",
    "\n",
    "            # Filter out genes that are too far away from the curve before refitting\n",
    "            predictions = covariates.values @ coeffs\n",
    "            pred_ratios = (\n",
    "                self[:, covariates.index].varm[\"genewise_dispersions\"] / predictions\n",
    "            )\n",
    "\n",
    "            targets.drop(\n",
    "                targets[(pred_ratios < 1e-4) | (pred_ratios >= 15)].index,\n",
    "                inplace=True,\n",
    "            )\n",
    "            covariates.drop(\n",
    "                covariates[(pred_ratios < 1e-4) | (pred_ratios >= 15)].index,\n",
    "                inplace=True,\n",
    "            )\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end - start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        self.uns[\"trend_coeffs\"] = pd.Series(coeffs, index=[\"a0\", \"a1\"])\n",
    "\n",
    "        self.varm[\"fitted_dispersions\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"fitted_dispersions\"][self.varm[\"non_zero\"]] = dispersion_trend(\n",
    "            self.varm[\"_normed_means\"][self.varm[\"non_zero\"]],\n",
    "            self.uns[\"trend_coeffs\"],\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def fit_dispersion_prior(self) -> None:\n",
    "        \"\"\"Fit dispersion variance priors and standard deviation of log-residuals.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that the dispersion trend curve was fitted. If not, fit it.\n",
    "        if \"fitted_dispersions\" not in self.varm:\n",
    "            self.fit_dispersion_trend()\n",
    "\n",
    "        # Exclude genes with all zeroes\n",
    "        num_samples = self.n_obs\n",
    "        num_vars = self.obsm[\"design_matrix\"].shape[-1]\n",
    "\n",
    "        # Check the degrees of freedom\n",
    "        if (num_samples - num_vars) <= 3:\n",
    "            warnings.warn(\n",
    "                \"As the residual degrees of freedom is less than 3, the distribution \"\n",
    "                \"of log dispersions is especially asymmetric and likely to be poorly \"\n",
    "                \"estimated by the MAD.\",\n",
    "                UserWarning,\n",
    "                stacklevel=2,\n",
    "            )\n",
    "\n",
    "        # Fit dispersions to the curve, and compute log residuals\n",
    "        disp_residuals = np.log(\n",
    "            self[:, self.non_zero_genes].varm[\"genewise_dispersions\"]\n",
    "        ) - np.log(self[:, self.non_zero_genes].varm[\"fitted_dispersions\"])\n",
    "\n",
    "        # Compute squared log-residuals and prior variance based on genes whose\n",
    "        # dispersions are above 100 * min_disp. This is to reproduce DESeq2's behaviour.\n",
    "        above_min_disp = self[:, self.non_zero_genes].varm[\"genewise_dispersions\"] >= (\n",
    "            100 * self.min_disp\n",
    "        )\n",
    "\n",
    "        self.uns[\"_squared_logres\"] = (\n",
    "            mean_absolute_deviation(disp_residuals[above_min_disp]) ** 2\n",
    "        )\n",
    "\n",
    "        self.uns[\"prior_disp_var\"] = np.maximum(\n",
    "            self.uns[\"_squared_logres\"] - polygamma(1, (num_samples - num_vars) / 2),\n",
    "            0.25,\n",
    "        )\n",
    "        \n",
    "    def fit_MAP_dispersions(self) -> None:\n",
    "        \"\"\"Fit Maximum a Posteriori dispersion estimates.\n",
    "\n",
    "        After MAP dispersions are fit, filter genes for which we don't apply shrinkage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that the dispersion prior variance is available. If not, compute it.\n",
    "        if \"prior_disp_var\" not in self.uns:\n",
    "            self.fit_dispersion_prior()\n",
    "\n",
    "        # Convert design matrix to numpy for speed\n",
    "        design_matrix = self.obsm[\"design_matrix\"].values\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting MAP dispersions...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "            res = Parallel(\n",
    "                n_jobs=self.n_processes,\n",
    "                verbose=self.joblib_verbosity,\n",
    "                batch_size=self.batch_size,\n",
    "            )(\n",
    "                delayed(fit_alpha_mle)(\n",
    "                    counts=self.X[:, i],\n",
    "                    design_matrix=design_matrix,\n",
    "                    mu=self.layers[\"_mu_hat\"][:, i],\n",
    "                    alpha_hat=self.varm[\"fitted_dispersions\"][i],\n",
    "                    min_disp=self.min_disp,\n",
    "                    max_disp=self.max_disp,\n",
    "                    prior_disp_var=self.uns[\"prior_disp_var\"].item(),\n",
    "                    cr_reg=True,\n",
    "                    prior_reg=True,\n",
    "                )\n",
    "                for i in self.non_zero_idx\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end-start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        dispersions_, l_bfgs_b_converged_ = zip(*res)\n",
    "\n",
    "        self.varm[\"MAP_dispersions\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"MAP_dispersions\"][self.varm[\"non_zero\"]] = np.clip(\n",
    "            dispersions_, self.min_disp, self.max_disp\n",
    "        )\n",
    "\n",
    "        self.varm[\"_MAP_converged\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"_MAP_converged\"][self.varm[\"non_zero\"]] = l_bfgs_b_converged_\n",
    "\n",
    "        # Filter outlier genes for which we won't apply shrinkage\n",
    "        self.varm[\"dispersions\"] = self.varm[\"MAP_dispersions\"].copy()\n",
    "        self.varm[\"_outlier_genes\"] = np.log(self.varm[\"genewise_dispersions\"]) > np.log(\n",
    "            self.varm[\"fitted_dispersions\"]\n",
    "        ) + 2 * np.sqrt(self.uns[\"_squared_logres\"])\n",
    "        self.varm[\"dispersions\"][self.varm[\"_outlier_genes\"]] = self.varm[\n",
    "            \"genewise_dispersions\"\n",
    "        ][self.varm[\"_outlier_genes\"]]\n",
    "        \n",
    "    def fit_LFC(self) -> None:\n",
    "        \"\"\"Fit log fold change (LFC) coefficients.\n",
    "\n",
    "        In the 2-level setting, the intercept corresponds to the base mean,\n",
    "        while the second is the actual LFC coefficient, in natural log scale.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check that MAP dispersions are available. If not, compute them.\n",
    "        if \"dispersions\" not in self.varm:\n",
    "            self.fit_MAP_dispersions()\n",
    "\n",
    "        # Convert design matrix to numpy for speed\n",
    "        design_matrix = self.obsm[\"design_matrix\"].values\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(\"Fitting LFCs...\", file=sys.stderr)\n",
    "        start = time.time()\n",
    "        with parallel_backend(\"loky\", inner_max_num_threads=1):\n",
    "            res = Parallel(\n",
    "                n_jobs=self.n_processes,\n",
    "                verbose=self.joblib_verbosity,\n",
    "                batch_size=self.batch_size,\n",
    "            )(\n",
    "                delayed(irls_solver)(\n",
    "                    counts=self.X[:, i],\n",
    "                    size_factors=self.obsm[\"size_factors\"],\n",
    "                    design_matrix=design_matrix,\n",
    "                    disp=self.varm[\"dispersions\"][i],\n",
    "                    min_mu=self.min_mu,\n",
    "                    beta_tol=self.beta_tol,\n",
    "                )\n",
    "                for i in self.non_zero_idx\n",
    "            )\n",
    "        end = time.time()\n",
    "\n",
    "        if not self.quiet:\n",
    "            print(f\"... done in {end-start:.2f} seconds.\\n\", file=sys.stderr)\n",
    "\n",
    "        MLE_lfcs_, mu_, hat_diagonals_, converged_ = zip(*res)\n",
    "        mu_ = np.array(mu_).T\n",
    "        hat_diagonals_ = np.array(hat_diagonals_).T\n",
    "\n",
    "        self.varm[\"LFC\"] = pd.DataFrame(\n",
    "            np.NaN,\n",
    "            index=self.var_names,\n",
    "            columns=self.obsm[\"design_matrix\"].columns,\n",
    "        )\n",
    "\n",
    "        self.varm[\"LFC\"].update(\n",
    "            pd.DataFrame(\n",
    "                MLE_lfcs_,\n",
    "                index=self.non_zero_genes,\n",
    "                columns=self.obsm[\"design_matrix\"].columns,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.layers[\"_mu_LFC\"] = np.full((self.n_obs, self.n_vars), np.NaN)\n",
    "        self.layers[\"_mu_LFC\"][:, self.varm[\"non_zero\"]] = mu_\n",
    "\n",
    "        self.layers[\"_hat_diagonals\"] = np.full((self.n_obs, self.n_vars), np.NaN)\n",
    "        self.layers[\"_hat_diagonals\"][:, self.varm[\"non_zero\"]] = hat_diagonals_\n",
    "\n",
    "        self.varm[\"_LFC_converged\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"_LFC_converged\"][self.varm[\"non_zero\"]] = converged_\n",
    "        \n",
    "    \n",
    "    def calculate_cooks(self) -> None:\n",
    "        if \"dispersions\" not in self.varm:\n",
    "            self.fit_MAP_dispersions()\n",
    "        num_vars = self.obsm[\"design_matrix\"].shape[-1]\n",
    "\n",
    "        # Keep only non-zero genes\n",
    "        nonzero_data = self[:, self.non_zero_genes]\n",
    "        normed_counts = pd.DataFrame(\n",
    "            nonzero_data.X / self.obsm[\"size_factors\"][:, None],\n",
    "            index=self.obs_names,\n",
    "            columns=self.non_zero_genes,\n",
    "        )\n",
    "        \n",
    "        dispersions = robust_method_of_moments_disp(\n",
    "            normed_counts, self.obsm[\"design_matrix\"]\n",
    "        )\n",
    "        V = (\n",
    "            nonzero_data.layers[\"_mu_LFC\"]\n",
    "            + dispersions.values[None, :] * nonzero_data.layers[\"_mu_LFC\"] ** 2\n",
    "        )\n",
    "        squared_pearson_res = (nonzero_data.X - nonzero_data.layers[\"_mu_LFC\"]) ** 2 / V\n",
    "        diag_mul = (\n",
    "            nonzero_data.layers[\"_hat_diagonals\"]\n",
    "            / (1 - nonzero_data.layers[\"_hat_diagonals\"]) ** 2\n",
    "        )\n",
    "\n",
    "        self.layers[\"cooks\"] = np.full((self.n_obs, self.n_vars), np.NaN)\n",
    "        self.layers[\"cooks\"][:, self.varm[\"non_zero\"]] = (\n",
    "            squared_pearson_res / num_vars * diag_mul\n",
    "        )\n",
    "        \n",
    "    def refit(self) -> None:\n",
    "        # Replace outlier counts\n",
    "        self._replace_outliers()\n",
    "        if not self.quiet:\n",
    "            print(\n",
    "                f\"Refitting {sum(self.varm['replaced']) } outliers.\\n\", file=sys.stderr\n",
    "            )\n",
    "\n",
    "        if sum(self.varm[\"replaced\"]) > 0:\n",
    "            # Refit dispersions and LFCs for genes that had outliers replaced\n",
    "            self._refit_without_outliers()\n",
    "            \n",
    "    \n",
    "    def _fit_MoM_dispersions(self) -> None:\n",
    "        # Check that size_factors are available. If not, compute them.\n",
    "        if \"normed_counts\" not in self.layers:\n",
    "            self.fit_size_factors()\n",
    "\n",
    "        rde = fit_rough_dispersions(\n",
    "            self.layers[\"normed_counts\"],\n",
    "            self.obsm[\"design_matrix\"],\n",
    "        )\n",
    "        mde = fit_moments_dispersions(\n",
    "            self.layers[\"normed_counts\"], self.obsm[\"size_factors\"]\n",
    "        )\n",
    "        alpha_hat = np.minimum(rde, mde)\n",
    "\n",
    "        self.varm[\"_MoM_dispersions\"] = np.full(self.n_vars, np.NaN)\n",
    "        self.varm[\"_MoM_dispersions\"][self.varm[\"non_zero\"]] = np.clip(\n",
    "            alpha_hat, self.min_disp, self.max_disp\n",
    "        )\n",
    "        \n",
    "\n",
    "    def plot_dispersions(\n",
    "        self, log: bool = True, save_path: Optional[str] = None, **kwargs\n",
    "    ) -> None:\n",
    "        disps = [\n",
    "            self.varm[\"genewise_dispersions\"],\n",
    "            self.varm[\"dispersions\"],\n",
    "            self.varm[\"fitted_dispersions\"],\n",
    "        ]\n",
    "        legend_labels = [\"Estimated\", \"Final\", \"Fitted\"]\n",
    "        make_scatter(\n",
    "            disps,\n",
    "            legend_labels=legend_labels,\n",
    "            x_val=self.varm[\"_normed_means\"],\n",
    "            log=log,\n",
    "            save_path=save_path,\n",
    "            **kwargs,\n",
    "        )\n",
    "    \n",
    "    def _replace_outliers(self) -> None:\n",
    "        # Check that cooks distances are available. If not, compute them.\n",
    "        if \"cooks\" not in self.layers:\n",
    "            self.calculate_cooks()\n",
    "        \n",
    "        num_samples = self.n_obs\n",
    "        num_vars = self.obsm[\"design_matrix\"].shape[1]\n",
    "        # Check whether cohorts have enough samples to allow refitting\n",
    "        n_or_more = (\n",
    "            self.obsm[\"design_matrix\"][\n",
    "                self.obsm[\"design_matrix\"].columns[-1]\n",
    "            ].value_counts()\n",
    "            >= self.min_replicates\n",
    "        )\n",
    "        if n_or_more.sum() == 0:\n",
    "            # No sample can be replaced. Set self.replaced to False and exit.\n",
    "            self.varm[\"replaced\"] = pd.Series(False, index=self.var_names)\n",
    "            return\n",
    "\n",
    "        replaceable = n_or_more[\n",
    "            self.obsm[\"design_matrix\"][self.obsm[\"design_matrix\"].columns[-1]]\n",
    "        ]\n",
    "\n",
    "        self.obsm[\"replaceable\"] = replaceable.values\n",
    "\n",
    "        # Get positions of counts with cooks above threshold\n",
    "        cooks_cutoff = f.ppf(0.99, num_vars, num_samples - num_vars)\n",
    "        idx = self.layers[\"cooks\"] > cooks_cutoff\n",
    "        self.varm[\"replaced\"] = idx.any(axis=0)\n",
    "\n",
    "        if sum(self.varm[\"replaced\"] > 0):\n",
    "            # Compute replacement counts: trimmed means * size_factors\n",
    "            self.counts_to_refit = self[:, self.varm[\"replaced\"]].copy()\n",
    "\n",
    "            trim_base_mean = pd.DataFrame(\n",
    "                cast(\n",
    "                    np.ndarray,\n",
    "                    trimmed_mean(\n",
    "                        self.counts_to_refit.X / self.obsm[\"size_factors\"][:, None],\n",
    "                        trim=0.2,\n",
    "                        axis=0,\n",
    "                    ),\n",
    "                ),\n",
    "                index=self.counts_to_refit.var_names,\n",
    "            )\n",
    "\n",
    "            replacement_counts = (\n",
    "                pd.DataFrame(\n",
    "                    trim_base_mean.values * self.obsm[\"size_factors\"],\n",
    "                    index=self.counts_to_refit.var_names,\n",
    "                    columns=self.counts_to_refit.obs_names,\n",
    "                )\n",
    "                .astype(int)\n",
    "                .T\n",
    "            )\n",
    "\n",
    "            self.counts_to_refit.X[\n",
    "                self.obsm[\"replaceable\"][:, None] & idx[:, self.varm[\"replaced\"]]\n",
    "            ] = replacement_counts.values[\n",
    "                self.obsm[\"replaceable\"][:, None] & idx[:, self.varm[\"replaced\"]]\n",
    "            ]\n",
    "\n",
    "\n",
    "      \n",
    "    def _refit_without_outliers(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        \"\"\"Re-run the whole DESeq2 pipeline with replaced outliers.\"\"\"\n",
    "        assert (\n",
    "            self.refit_cooks\n",
    "        ), \"Trying to refit Cooks outliers but the 'refit_cooks' flag is set to False\"\n",
    "\n",
    "        # Check that _replace_outliers() was previously run.\n",
    "        if \"replaced\" not in self.varm:\n",
    "            self._replace_outliers()\n",
    "\n",
    "        # Only refit genes for which replacing outliers hasn't resulted in all zeroes\n",
    "        new_all_zeroes = (self.counts_to_refit.X == 0).all(axis=0)\n",
    "        self.new_all_zeroes_genes = self.counts_to_refit.var_names[new_all_zeroes]\n",
    "        if (~new_all_zeroes).sum() == 0:  # if no gene can be refit, we can skip\n",
    "            return\n",
    "\n",
    "        self.counts_to_refit = self.counts_to_refit[:, ~new_all_zeroes].copy()\n",
    "        if isinstance(self.new_all_zeroes_genes, pd.MultiIndex):\n",
    "            raise ValueError\n",
    "\n",
    "        sub_dds = DeseqDataSet(\n",
    "            counts=pd.DataFrame(\n",
    "                self.counts_to_refit.X,\n",
    "                index=self.counts_to_refit.obs_names,\n",
    "                columns=self.counts_to_refit.var_names,\n",
    "            ),\n",
    "            metadata=self.obs,\n",
    "            design_factors=self.design_factors,\n",
    "            ref_level=self.ref_level,\n",
    "            min_mu=self.min_mu,\n",
    "            min_disp=self.min_disp,\n",
    "            max_disp=self.max_disp,\n",
    "            refit_cooks=self.refit_cooks,\n",
    "            min_replicates=self.min_replicates,\n",
    "            beta_tol=self.beta_tol,\n",
    "            n_cpus=self.n_processes,\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "\n",
    "        # Use the same size factors\n",
    "        sub_dds.obsm[\"size_factors\"] = self.counts_to_refit.obsm[\"size_factors\"]\n",
    "\n",
    "        # Estimate gene-wise dispersions.\n",
    "        sub_dds.fit_genewise_dispersions()\n",
    "\n",
    "        # Compute trend dispersions.\n",
    "        # Note: the trend curve is not refitted.\n",
    "        sub_dds.uns[\"trend_coeffs\"] = self.uns[\"trend_coeffs\"]\n",
    "        sub_dds.varm[\"_normed_means\"] = (\n",
    "            self.counts_to_refit.X / self.counts_to_refit.obsm[\"size_factors\"][:, None]\n",
    "        ).mean(0)\n",
    "        sub_dds.varm[\"fitted_dispersions\"] = dispersion_trend(\n",
    "            sub_dds.varm[\"_normed_means\"],\n",
    "            sub_dds.uns[\"trend_coeffs\"],\n",
    "        )\n",
    "\n",
    "        # Estimate MAP dispersions.\n",
    "        # Note: the prior variance is not recomputed.\n",
    "        sub_dds.uns[\"_squared_logres\"] = self.uns[\"_squared_logres\"]\n",
    "        sub_dds.uns[\"prior_disp_var\"] = self.uns[\"prior_disp_var\"]\n",
    "\n",
    "        sub_dds.fit_MAP_dispersions()\n",
    "\n",
    "        # Estimate log-fold changes (in natural log scale)\n",
    "        sub_dds.fit_LFC()\n",
    "\n",
    "        # Replace values in main object\n",
    "        to_replace = self.varm[\"replaced\"].copy()\n",
    "        # Only replace if genes are not all zeroes after outlier replacement\n",
    "        to_replace[to_replace] = ~new_all_zeroes\n",
    "\n",
    "        self.varm[\"_normed_means\"][to_replace] = sub_dds.varm[\"_normed_means\"]\n",
    "        self.varm[\"LFC\"][to_replace] = sub_dds.varm[\"LFC\"]\n",
    "        self.varm[\"dispersions\"][to_replace] = sub_dds.varm[\"dispersions\"]\n",
    "\n",
    "        replace_cooks = pd.DataFrame(self.layers[\"cooks\"].copy())\n",
    "        replace_cooks.loc[self.obsm[\"replaceable\"], to_replace] = 0.0\n",
    "\n",
    "        self.layers[\"replace_cooks\"] = replace_cooks\n",
    "        # Take into account new all-zero genes\n",
    "        if (new_all_zeroes).sum() > 0:\n",
    "            self[:, self.new_all_zeroes_genes].varm[\"_normed_means\"] = np.zeros(\n",
    "                new_all_zeroes.sum()\n",
    "            )\n",
    "            self[:, self.new_all_zeroes_genes].varm[\"LFC\"] = np.zeros(\n",
    "                new_all_zeroes.sum()\n",
    "            )\n",
    "    \n",
    "    def _fit_iterate_size_factors(self, niter: int = 10, quant: float = 0.95) -> None:\n",
    "        \"\"\"\n",
    "        Fit size factors using the ``iterative`` method.\n",
    "\n",
    "        Used when each gene has at least one zero.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        niter : int\n",
    "            Maximum number of iterations to perform (default: ``10``).\n",
    "\n",
    "        quant : float\n",
    "            Quantile value at which negative likelihood is cut in the optimization\n",
    "            (default: ``0.95``).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize size factors and normed counts fields\n",
    "        self.obsm[\"size_factors\"] = np.ones(self.n_obs)\n",
    "        self.layers[\"normed_counts\"] = self.X\n",
    "\n",
    "        # Reduce the design matrix to an intercept and reconstruct at the end\n",
    "        self.obsm[\"design_matrix_buffer\"] = self.obsm[\"design_matrix\"].copy()\n",
    "        self.obsm[\"design_matrix\"] = pd.DataFrame(\n",
    "            1, index=self.obs_names, columns=[[\"intercept\"]]\n",
    "        )\n",
    "\n",
    "        # Fit size factors using MLE\n",
    "        def objective(p):\n",
    "            sf = np.exp(p - np.mean(p))\n",
    "            nll = nb_nll(\n",
    "                counts=self[:, self.non_zero_genes].X,\n",
    "                mu=self[:, self.non_zero_genes].layers[\"_mu_hat\"]\n",
    "                / self.obsm[\"size_factors\"][:, None]\n",
    "                * sf[:, None],\n",
    "                alpha=self[:, self.non_zero_genes].varm[\"dispersions\"],\n",
    "            )\n",
    "            # Take out the lowest likelihoods (highest neg) from the sum\n",
    "            return np.sum(nll[nll < np.quantile(nll, quant)])\n",
    "\n",
    "        for i in range(niter):\n",
    "            # Estimate dispersions based on current size factors\n",
    "            self.fit_genewise_dispersions()\n",
    "\n",
    "            # Use a mean trend curve\n",
    "            use_for_mean_genes = self.var_names[\n",
    "                (self.varm[\"genewise_dispersions\"] > 10 * self.min_disp)\n",
    "                & self.varm[\"non_zero\"]\n",
    "            ]\n",
    "\n",
    "            mean_disp = trimmed_mean(\n",
    "                self[:, use_for_mean_genes].varm[\"genewise_dispersions\"], trim=0.001\n",
    "            )\n",
    "            self.varm[\"fitted_dispersions\"] = np.ones(self.n_vars) * mean_disp\n",
    "            self.fit_dispersion_prior()\n",
    "            self.fit_MAP_dispersions()\n",
    "            old_sf = self.obsm[\"size_factors\"].copy()\n",
    "\n",
    "            # Fit size factors using MLE\n",
    "            res = minimize(objective, np.log(old_sf), method=\"Powell\")\n",
    "\n",
    "            self.obsm[\"size_factors\"] = np.exp(res.x - np.mean(res.x))\n",
    "\n",
    "            if not res.success:\n",
    "                print(\"A size factor fitting iteration failed.\", file=sys.stderr)\n",
    "                break\n",
    "\n",
    "            if (i > 1) and np.sum(\n",
    "                (np.log(old_sf) - np.log(self.obsm[\"size_factors\"])) ** 2\n",
    "            ) < 1e-4:\n",
    "                break\n",
    "            elif i == niter - 1:\n",
    "                print(\"Iterative size factor fitting did not converge.\", file=sys.stderr)\n",
    "\n",
    "        # Restore the design matrix and free buffer\n",
    "        self.obsm[\"design_matrix\"] = self.obsm[\"design_matrix_buffer\"].copy()\n",
    "        del self.obsm[\"design_matrix_buffer\"]\n",
    "\n",
    "        # Store normalized counts\n",
    "        self.layers[\"normed_counts\"] = self.X / self.obsm[\"size_factors\"][:, None]\n",
    "        \n",
    "    def _check_full_rank_design(self):\n",
    "        \"\"\"Check that the design matrix has full column rank.\"\"\"\n",
    "        rank = np.linalg.matrix_rank(self.obsm[\"design_matrix\"])\n",
    "        num_vars = self.obsm[\"design_matrix\"].shape[1]\n",
    "\n",
    "        if rank < num_vars:\n",
    "            warnings.warn(\n",
    "                \"The design matrix is not full rank, so the model cannot be \"\n",
    "                \"fitted, but some operations like design-free VST remain possible. \"\n",
    "                \"To perform differential expression analysis, please remove the design \"\n",
    "                \"variables that are linear combinations of others.\",\n",
    "                UserWarning,\n",
    "                stacklevel=2,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe542c7-b172-4456-9ea2-15c303427460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "counts = pd.read_csv('data_simulation/sim1_sampled_cnv/rna_mixed_cnv.csv', index_col=0)\n",
    "counts = counts.T\n",
    "metadata = pd.read_csv('data_simulation/sim1_sampled_cnv/metadata.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5266efef-5d84-4377-a341-ac7ccf7aad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pydeseqCN(counts, metadata):\n",
    "    \n",
    "    # Create dds object\n",
    "    dds = DeseqDataSet(\n",
    "        counts=counts,\n",
    "        metadata=metadata,\n",
    "        design_factors=\"condition\",\n",
    "        refit_cooks=False,\n",
    "        n_cpus=8\n",
    "    )\n",
    "    dds.deseq2()\n",
    "    # Statistical test\n",
    "    stat_res = DeseqStats(dds, \n",
    "                      contrast=['condition', 'B', 'A'], \n",
    "                      alpha=0.05, \n",
    "                      cooks_filter=False, \n",
    "                      independent_filter=True, \n",
    "                      prior_LFC_var=None, \n",
    "                      lfc_null=0.0, \n",
    "                      alt_hypothesis=None, \n",
    "                      inference=None, quiet=False\n",
    "                         )\n",
    "    stat_res.summary()\n",
    "    # LFC shrinkage (apeGLM) \n",
    "    stat_res.lfc_shrink(coeff=\"condition_B_vs_A\")\n",
    "    res_df = stat_res.results_df\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9d38e62-c8b4-483e-b88b-6b3e9c212e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting size factors...\n",
      "... done in 0.05 seconds.\n",
      "\n",
      "Fitting dispersions...\n",
      "... done in 1.11 seconds.\n",
      "\n",
      "Fitting dispersion trend curve...\n",
      "... done in 0.71 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 1.30 seconds.\n",
      "\n",
      "Fitting LFCs...\n",
      "... done in 0.63 seconds.\n",
      "\n",
      "Running Wald tests...\n",
      "... done in 0.44 seconds.\n",
      "\n",
      "Fitting MAP LFCs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log2 fold change & Wald test p-value: condition B vs A\n",
      "           baseMean  log2FoldChange     lfcSE       stat        pvalue  \\\n",
      "g1         2.171280        1.933201  0.369055   5.238243  1.621123e-07   \n",
      "g2        15.511650        2.172559  0.331971   6.544414  5.972916e-11   \n",
      "g3       235.482136        1.838344  0.230182   7.986465  1.388629e-15   \n",
      "g4      1695.155932        1.985842  0.224824   8.832867  1.020267e-18   \n",
      "g5       459.244451        1.928127  0.178013  10.831404  2.443787e-27   \n",
      "...             ...             ...       ...        ...           ...   \n",
      "g14996  9719.742293        0.057358  0.152538   0.376026  7.068979e-01   \n",
      "g14997    18.194573        0.244528  0.373721   0.654307  5.129141e-01   \n",
      "g14998    96.463547       -0.023445  0.193009  -0.121473  9.033166e-01   \n",
      "g14999   376.386660       -0.387665  0.377669  -1.026467  3.046715e-01   \n",
      "g15000   443.768206        0.077620  0.157256   0.493590  6.215960e-01   \n",
      "\n",
      "                padj  \n",
      "g1      5.539144e-06  \n",
      "g2      2.627382e-09  \n",
      "g3      7.629828e-14  \n",
      "g4      6.457385e-17  \n",
      "g5      2.320051e-25  \n",
      "...              ...  \n",
      "g14996  9.997058e-01  \n",
      "g14997  9.997058e-01  \n",
      "g14998  9.997058e-01  \n",
      "g14999  9.997058e-01  \n",
      "g15000  9.997058e-01  \n",
      "\n",
      "[15000 rows x 6 columns]\n",
      "Shrunk log2 fold change & Wald test p-value: condition B vs A\n",
      "           baseMean  log2FoldChange     lfcSE       stat        pvalue  \\\n",
      "g1         2.171280        1.787447  0.370728   5.238243  1.621123e-07   \n",
      "g2        15.511650        2.068579  0.336068   6.544414  5.972916e-11   \n",
      "g3       235.482136        1.776324  0.232108   7.986465  1.388629e-15   \n",
      "g4      1695.155932        1.916474  0.225277   8.832867  1.020267e-18   \n",
      "g5       459.244451        1.885262  0.178908  10.831404  2.443787e-27   \n",
      "...             ...             ...       ...        ...           ...   \n",
      "g14996  9719.742293        0.086555  0.140919   0.376026  7.068979e-01   \n",
      "g14997    18.194573        0.063588  0.250671   0.654307  5.129141e-01   \n",
      "g14998    96.463547       -0.012960  0.163342  -0.121473  9.033166e-01   \n",
      "g14999   376.386660       -0.101114  0.254509  -1.026467  3.046715e-01   \n",
      "g15000   443.768206        0.051924  0.141342   0.493590  6.215960e-01   \n",
      "\n",
      "                padj  \n",
      "g1      5.539144e-06  \n",
      "g2      2.627382e-09  \n",
      "g3      7.629828e-14  \n",
      "g4      6.457385e-17  \n",
      "g5      2.320051e-25  \n",
      "...              ...  \n",
      "g14996  9.997058e-01  \n",
      "g14997  9.997058e-01  \n",
      "g14998  9.997058e-01  \n",
      "g14999  9.997058e-01  \n",
      "g15000  9.997058e-01  \n",
      "\n",
      "[15000 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... done in 1.26 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res2_cnv = test_pydeseqCN(counts, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8385ed3e-6706-4beb-9ee1-95c5d4fb7471",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6282e460-42b5-4633-b2fc-a82e2dc9ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the path to directory where you would like results to be saved\n",
    "OUTPUT_PATH = \"data_simulation/results/\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)  # Create path if it doesn't exist\n",
    "res2_cnv.to_csv(os.path.join(OUTPUT_PATH, \"res2_cnv.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7480b3cf-c5f3-42bd-b07e-2a9abf9a160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stat_res.plot_MA(s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a647e-7e6f-4d57-89cb-b80745302117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
